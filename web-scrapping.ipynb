{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "import bs4\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "from selenium import webdriver\n",
    "import json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get a specific type of news"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "download chromedriver version similar to your chrome browser   \n",
    "https://sites.google.com/a/chromium.org/chromedriver/downloads\n",
    "\n",
    "installation:\n",
    "```\n",
    "$ unzp chromedriver_linux64.zip\n",
    "$ sudo mv chromedriver /usr/bin/chromedriver\n",
    "$ sudo chown root:root /usr/bin/chromedriver\n",
    "$ sudo chmod +x /usr/bin/chromedriver\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_site = \"https://data.covid19.go.id/public/index.html\"\n",
    "\n",
    "options = webdriver.ChromeOptions()\n",
    "options.add_argument(\"headless\")\n",
    "\n",
    "driver = webdriver.Chrome(executable_path=\"/usr/bin/chromedriver\", \n",
    "                          options=options)\n",
    "driver.get(base_site)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "soup_page = BeautifulSoup(driver.page_source, parser='html5lib')\n",
    "soup_page_str = str(soup_page)\n",
    "#print(type(soup_page))\n",
    "#print(soup_page.prettify())\n",
    "soup_page_str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "soup_page = BeautifulSoup(soup_page_str, parser='html5lib')\n",
    "\n",
    "time_stamp = [data.get_text().split()[-1] \n",
    "              for data in soup_page.find_all('span', attrs={'class': 'pull-right'}) \n",
    "                  if 'Tanggal' in data.get_text()]\n",
    "time_stamp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Dataset is up to: {time_stamp[0]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "headlines = [[headline_data.find('h3').string] + [data.string for data in headline_data.find_all('b')]\n",
    "             for headline_data in soup_page.find_all('div', attrs={'class': 'col-md-3'})]\n",
    "headlines = {label.lower(): [total_case, increment.lower()]\n",
    "             for total_case, label, increment in headlines}\n",
    "headlines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for headline in headlines:\n",
    "    label, val = list(headline.items())[0]\n",
    "    print(f\"{label:>16s}: {val[0]} orang ({val[1]})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "provinces_data = {data.find('b').get_text().strip().lower()\\\n",
    "                   : data.find('span').string[15:]\n",
    "                  for data in soup_page.find_all('div', attrs={'class': 'wrapDetailInfo'})}\n",
    "provinces_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "provinces_data['jawa timur']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "not None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = {'time_stamp': time_stamp, \n",
    "        'headlines': headlines,\n",
    "        'provinces_data': provinces_data}\n",
    "\n",
    "json_data = json.dumps(data, indent=4)\n",
    "\n",
    "with open(\"covid_19.json\", \"w\") as f:\n",
    "    f.write(json_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"covid_19.json\", \"r\") as f:\n",
    "    data = f.read()\n",
    "    \n",
    "print(json.loads(data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from threading import Thread\n",
    "from multiprocessing import Process, Manager\n",
    "\n",
    "class WorkerFunc(object):\n",
    "    def __init__(self, queue_dict):\n",
    "        self.queue_dict = queue_dict\n",
    "        \n",
    "    def worker(self, bs):\n",
    "        a = [bs, \"a\", 1]\n",
    "        self.queue_dict[0] = a\n",
    "        time.sleep(3)\n",
    "        \n",
    "        \n",
    "class CountdownTask: \n",
    "    def __init__(self): \n",
    "        self._running = True\n",
    "      \n",
    "    def terminate(self): \n",
    "        self._running = False\n",
    "      \n",
    "    def counter(self): \n",
    "        while self._running: \n",
    "            print(\".\", end=\"\") \n",
    "            time.sleep(0.5) \n",
    "\n",
    "if __name__ == '__main__':\n",
    "    manager = Manager()\n",
    "\n",
    "    return_dict = manager.dict()\n",
    "    print(return_dict.values())\n",
    "\n",
    "    counter_fun = CountdownTask() \n",
    "    counter_proc = Thread(target=counter_fun.counter) \n",
    "    counter_proc.start() \n",
    "    #print(os.getpid())\n",
    "    \n",
    "    # Signal termination \n",
    "    worker_fun = WorkerFunc(return_dict)\n",
    "    p1 = Process(target=worker_fun.worker,args=(bs4.BeautifulSoup, ))\n",
    "    p1.start()\n",
    "    p1.join()\n",
    "    if not p1.is_alive():\n",
    "        counter_fun.terminate()\n",
    "        counter_proc.join()\n",
    "\n",
    "    print(return_dict.values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n",
      "......."
     ]
    }
   ],
   "source": [
    "import bs4\n",
    "import sys\n",
    "import time\n",
    "\n",
    "from threading import Thread\n",
    "from multiprocessing import Process, Manager\n",
    "\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "from selenium import webdriver\n",
    "\n",
    "#sys.setrecursionlimit(1000)\n",
    "\n",
    "class WorkerTask(object):\n",
    "    def __init__(self, queue_dict):\n",
    "        self.queue_dict = queue_dict\n",
    "        \n",
    "    def worker(self):\n",
    "        base_site = \"https://data.covid19.go.id/public/index.html\"\n",
    "        \n",
    "        options = webdriver.ChromeOptions()\n",
    "        options.add_argument(\"headless\")\n",
    "        driver = webdriver.Chrome(executable_path=\"/usr/bin/chromedriver\", options=options)\n",
    "        driver.get(base_site)\n",
    "        \n",
    "        soup_page = BeautifulSoup(driver.page_source, parser=\"html5lib\", features=\"lxml\")\n",
    "        \n",
    "        self.queue_dict[0] = str(soup_page)\n",
    "        #time.sleep(3)\n",
    "        \n",
    "        \n",
    "class ProgressTask: \n",
    "    def __init__(self): \n",
    "        self._running = True\n",
    "      \n",
    "    def terminate(self): \n",
    "        self._running = False\n",
    "      \n",
    "    def print_point(self): \n",
    "        while self._running: \n",
    "            sys.stdout.write(\".\") \n",
    "            time.sleep(1) \n",
    "\n",
    "\n",
    "def scrap_covid19_go_id():\n",
    "    queue_dict = Manager().dict()\n",
    "    print(queue_dict.values())\n",
    "\n",
    "    progress_ins = ProgressTask() \n",
    "    progress_proc = Thread(target=progress_ins.print_point) \n",
    "    progress_proc.start() \n",
    "    #print(os.getpid())\n",
    "    \n",
    "    # Signal termination \n",
    "    worker_ins = WorkerTask(queue_dict)\n",
    "    worker_proc = Process(target=worker_ins.worker)\n",
    "    worker_proc.start()\n",
    "    worker_proc.join()\n",
    "    \n",
    "    if not worker_proc.is_alive():\n",
    "        progress_ins.terminate()\n",
    "        progress_proc.join()\n",
    "\n",
    "    #print(queue_dict.values())\n",
    "    soup_page = BeautifulSoup(queue_dict.values()[0], parser=\"lxml\", features=\"lxml\")\n",
    "    \n",
    "    return soup_page\n",
    "\n",
    "            \n",
    "if __name__ == '__main__':\n",
    "    soup_page = scrap_covid19_go_id()\n",
    "    #print(soup_page.prettify())\n",
    "    #print(type(soup_page))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python web-scrapping.py -f True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
